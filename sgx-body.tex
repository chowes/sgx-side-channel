\section{Intel SGX}

Intel Software Guard Extensions (SGX) is an extension to the Intel architecture designed to allow programs to run securely in an environment where all software on the host machine is potentially untrusted \cite{intel_corporation_intel_2016}. SGX was designed to address the problem of \emph{secure remote computation}, that is, secure execution of software on a remote system controlled by an untrusted party \cite{intel_corporation_intel_2016}. Under this threat model, \emph{all} software on a remote system is potentially malicious, including privileged software such as the operating system and hypervisor. Thus SGX must provide protection to user-level programs from untrusted software running at user level as well as at higher privilege levels \cite{costan_intel_2016}. 

SGX provides confidentiality and integrity guarantees through the use of trusted hardware that sequesters a user-level program into a secure container called an \emph{enclave}, and then proves to a user through \emph{software attestation} that he or she is running unmodified software protected in an enclave by secure hardware \cite{intel_corporation_intel_2016}. In order to provide software attestation, the host machine provides a cryptographic signature certifying an enclave's measurement hash, which is computed on a measurement of its contents after it is loaded and initialized \cite{costan_intel_2016}. The remote user can then verify this signature against an endorsement certificate provided by the hardware manufacturer, and can refuse to load his or her data into an enclave whose measurement hash differs from the expected value \cite{intel_corporation_intel_2016, costan_intel_2016}. Under this threat model, the remote user need only trust the hardware manufacturer responsible for providing the secure hardware and endorsement certificate.

\subsection{SGX Enclaves}

The SGX security model is centered around maintaining security-sensitive information in secure containers isolated from the rest of the untrusted host system. SGX accomplishes this through the use of a contiguous range of protected memory called Processor Reserved Memory, which is accessible only via a set of specialized microcode instructions called from within an enclave \cite{costan_intel_2016}. Enclave contents and meta-data are stored in a subset of Processor Reserved Memory called the Enclave Page Cache, which is split into 4 KB pages. Management of enclave pages is delegated to the untrusted host OS or hypervisor, which can allocate or free enclave pages using SGX instructions, but may not access this memory directly. Rather, enclave pages are encrypted while in DRAM, and are decrypted in hardware as they are loaded into the cache by the CPU. Furthermore, memory management decisions made by system software are tracked in order to maintain isolation of protected memory by verifying that enclave pages can only be accessed by enclave code executing in the enclave associated with a given enclave page \cite{intel_corporation_intel_2016, costan_intel_2016, moghimi_cachezoom:_2017}. 

\section{Software Side-Channel Attacks}

Side-channel attacks are a class of attacks that leverage information about the physical properties of a system in order to carry out an attack. While physical side-channel attacks against modern hardware are difficult and costly, requiring advanced tools and physical access to the victim machine, software side-channel attacks are inexpensive to deploy and can be executed by anyone with remote or local access to a system \cite{costan_intel_2016}. The software side-channel attacks discussed here exploit hardware and software implementation details to acquire information about memory access patterns, which can be used to infer secrets from an otherwise secure system \cite{gotzfried_cache_2017, schwarz_malware_2017, xu_controlled-channel_2015, shinde_preventing_2015}. 

Cache timing attacks are used to infer memory access information by exploiting timing differences. Briefly, cache timing attacks take advantage of an otherwise desirable property of caching - accessing data stored in a chance is considerably faster than accessing data stored in memory. 
% describe how/why caching is used, including last level cache (global to all logical processors?)

An attacker can take advantage of this difference in access speed by filling the last level cache with data, thereby evicting data used by other processors, and measuring the time it takes to access this data after a context switch. The attacker can determine which regions of memory were accessed by the victim based on the time it takes to access the data it had previously placed in the cache. In effect, the attacker can infer information about the victim's memory usage patterns at page level granularity, which can be used to extract secrets such as encryption keys.

Page fault attacks can be employed by a malicious operating system to determine when a program is accessing specific pages. Page fault attacks are similar to cache timing attacks, in that an attacker moves a large number of pages into memory and leverages kernel-level information about page faults to determine which pages are used by a victim process.

\section{Attacks Against SGX Enclaves}

Both cache timing attacks and page fault attacks have been demonstrated against SGX enclaves in proof-of-concept attacks. While enclave data is protected in processor-reserved memory, memory management is deferred to the untrusted OS and hypervisor. 

Kernel level attacks...

User level attacks... Moreover, since even privileged services are oblivious to the contents and behavior of SGX enclaves, the protections enjoyed by enclave programs may also be used by attackers to disguise malware. A host OS has no means to monitor its SGX enclaves for malicious behavior, and as such cannot protect honest user-level process from malicious enclave behavior. 

\section{Countermeasures}

A number of countermeasures have been proposed, both for future development of secure hardware, and additional security measures that can be employed by security conscious developers working with the current implementation of SGX.

\section{Future Directions}

\section{Conclusions}
